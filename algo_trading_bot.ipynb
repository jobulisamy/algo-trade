{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e3a1a85",
   "metadata": {},
   "source": [
    "# Cell 1: Imports and Setup\n",
    "\n",
    "This cell imports all necessary libraries for the algorithmic trading bot.\n",
    "\n",
    "Key Components:\n",
    "- Core libraries: pandas, numpy, datetime\n",
    "- ML libraries: sklearn, xgboost, tensorflow\n",
    "- Trading: alpaca-py\n",
    "- Utilities: tqdm for progress, logging for monitoring\n",
    "- Visualization: matplotlib, seaborn\n",
    "\n",
    "Setup:\n",
    "- Suppress warnings for clean output\n",
    "- Configure matplotlib for inline plotting\n",
    "- Set random seeds for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8997c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports loaded successfully!\n",
      "Pandas version: 2.1.4\n",
      "NumPy version: 1.26.2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ALGORITHMIC TRADING BOT - CELL 1: IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "# Core Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "\n",
    "# Environment and Configuration\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Trading API (alpaca-py)\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from alpaca.trading.client import TradingClient\n",
    "from alpaca.trading.requests import MarketOrderRequest, GetOrdersRequest\n",
    "from alpaca.trading.enums import OrderSide, TimeInForce\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Deep Learning (TensorFlow/Keras will be imported only in the LSTM cell)\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential, load_model\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# tf.get_logger().setLevel('ERROR')  # Suppress TF warnings\n",
    "\n",
    "# Technical Analysis\n",
    "import talib\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "%matplotlib inline\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "# tf.random.set_seed(42)  # Only set in LSTM cell if needed\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('bot.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"All imports loaded successfully!\")\n",
    "# print(f\"TensorFlow version: {tf.__version__}\")  # Only print in LSTM cell\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362da9e2",
   "metadata": {},
   "source": [
    "# Cell 2: Configuration\n",
    "\n",
    "This cell defines all configuration parameters using a dataclass for clean organization.\n",
    "\n",
    "Key Features:\n",
    "- Environment variable loading with python-dotenv\n",
    "- Risk management parameters\n",
    "- Trading universe (15 liquid symbols)\n",
    "- ML model parameters\n",
    "- Operational settings\n",
    "\n",
    "Security:\n",
    "- API credentials loaded from environment variables\n",
    "- Paper trading mode enabled by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815aaaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class TradingConfig:\n",
    "    \"\"\"Configuration class for algorithmic trading bot\"\"\"\n",
    "    \n",
    "    # API Configuration\n",
    "    ALPACA_API_KEY: str = os.getenv('ALPACA_API_KEY', '')\n",
    "    ALPACA_SECRET_KEY: str = os.getenv('ALPACA_SECRET_KEY', '')\n",
    "    ALPACA_BASE_URL: str = 'https://paper-api.alpaca.markets/v2'  # Paper trading\n",
    "    \n",
    "    # Portfolio Settings\n",
    "    INITIAL_CAPITAL: float = 100000.0  # $100K paper trading\n",
    "    MAX_POSITION_PCT: float = 0.15     # 15% per symbol\n",
    "    MAX_TOTAL_EXPOSURE: float = 0.90   # 90% invested max\n",
    "    MIN_POSITION_VALUE: float = 1000   # Minimum $1K position\n",
    "    \n",
    "    # Risk Management\n",
    "    STOP_LOSS: float = 0.03            # 3% stop loss\n",
    "    TAKE_PROFIT: float = 0.07          # 7% take profit\n",
    "    MAX_DAILY_LOSS_PCT: float = 0.03   # 3% daily loss limit\n",
    "    MIN_SIGNAL_STRENGTH: float = 0.55  # Minimum signal confidence\n",
    "    \n",
    "    # Trading Universe (15 liquid symbols)\n",
    "    SYMBOLS: List[str] = None\n",
    "    \n",
    "    # Operational Settings\n",
    "    CHECK_INTERVAL: int = 300          # 5 minutes\n",
    "    CACHE_DURATION: int = 300          # 5 min cache\n",
    "    ML_LOOKBACK: int = 60             # 60 days for training\n",
    "    LSTM_SEQUENCE: int = 30           # 30-day sequences\n",
    "    RETRAIN_DAYS: int = 7             # Weekly retraining\n",
    "    \n",
    "    # Ensemble Weights (sum = 1.0)\n",
    "    STRATEGY_WEIGHTS: Dict[str, float] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.SYMBOLS is None:\n",
    "            self.SYMBOLS = [\n",
    "                'SPY', 'QQQ', 'IWM', 'DIA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN',\n",
    "                'NVDA', 'META', 'TSLA', 'JPM', 'V', 'WMT', 'DIS'\n",
    "            ]\n",
    "        \n",
    "        if self.STRATEGY_WEIGHTS is None:\n",
    "            self.STRATEGY_WEIGHTS = {\n",
    "                'rsi_mean_reversion': 0.12,\n",
    "                'momentum_breakout': 0.12,\n",
    "                'macd_volume': 0.10,\n",
    "                'gap_fade': 0.08,\n",
    "                'random_forest': 0.18,\n",
    "                'xgboost': 0.18,\n",
    "                'lstm': 0.22\n",
    "            }\n",
    "    \n",
    "    def validate_config(self) -> bool:\n",
    "        \"\"\"Validate configuration settings\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        if not self.ALPACA_API_KEY:\n",
    "            errors.append(\"ALPACA_API_KEY not found in environment variables\")\n",
    "        if not self.ALPACA_SECRET_KEY:\n",
    "            errors.append(\"ALPACA_SECRET_KEY not found in environment variables\")\n",
    "        if sum(self.STRATEGY_WEIGHTS.values()) != 1.0:\n",
    "            errors.append(f\"Strategy weights sum to {sum(self.STRATEGY_WEIGHTS.values())}, should be 1.0\")\n",
    "        \n",
    "        if errors:\n",
    "            for error in errors:\n",
    "                logger.error(error)\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "# Initialize configuration\n",
    "config = TradingConfig()\n",
    "\n",
    "# Display current configuration\n",
    "print(\"Trading Bot Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Initial Capital: ${config.INITIAL_CAPITAL:,.0f}\")\n",
    "print(f\"Max Position: {config.MAX_POSITION_PCT:.1%} per symbol\")\n",
    "print(f\"Max Exposure: {config.MAX_TOTAL_EXPOSURE:.1%}\")\n",
    "print(f\"Stop Loss: {config.STOP_LOSS:.1%}\")\n",
    "print(f\"Take Profit: {config.TAKE_PROFIT:.1%}\")\n",
    "print(f\"Check Interval: {config.CHECK_INTERVAL}s\")\n",
    "print(f\"Trading Universe: {len(config.SYMBOLS)} symbols\")\n",
    "print(f\"Symbols: {', '.join(config.SYMBOLS[:5])}...\")\n",
    "\n",
    "print(\"\\nStrategy Weights:\")\n",
    "for strategy, weight in config.STRATEGY_WEIGHTS.items():\n",
    "    print(f\"  {strategy}: {weight:.1%}\")\n",
    "\n",
    "# Validate configuration\n",
    "if config.validate_config():\n",
    "    print(\"\\nConfiguration validated successfully!\")\n",
    "else:\n",
    "    print(\"\\nConfiguration validation failed!\")\n",
    "    print(\"Please check your environment variables and settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b010c",
   "metadata": {},
   "source": [
    "# Cell 3: Data Layer\n",
    "\n",
    "This cell implements data fetching with intelligent caching to minimize API calls.\n",
    "\n",
    "Classes:\n",
    "- DataFetcher: Handles Alpaca API calls with 5-minute caching\n",
    "- FeatureEngine: Adds 25+ technical indicators\n",
    "\n",
    "Features:\n",
    "- Automatic retry logic for API failures\n",
    "- Memory-efficient caching system\n",
    "- Comprehensive technical analysis features\n",
    "- Error handling with fallback to cached data\n",
    "\n",
    "Test: Fetches SPY data and displays feature summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f9288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: DATA LAYER\n",
    "# ============================================================================\n",
    "\n",
    "class DataFetcher:\n",
    "    \"\"\"Handles data fetching from Alpaca API with caching\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str, secret_key: str, base_url: str):\n",
    "        self.api = tradeapi.REST(api_key, secret_key, base_url, api_version='v2')\n",
    "        self.cache = {}\n",
    "        self.cache_duration = config.CACHE_DURATION\n",
    "    \n",
    "    def _get_cache_key(self, symbol: str, days: int) -> str:\n",
    "        \"\"\"Generate cache key for symbol and timeframe\"\"\"\n",
    "        return f\"{symbol}_{days}\"\n",
    "    \n",
    "    def _is_cache_valid(self, cache_key: str) -> bool:\n",
    "        \"\"\"Check if cached data is still valid\"\"\"\n",
    "        if cache_key not in self.cache:\n",
    "            return False\n",
    "        \n",
    "        cache_time = self.cache[cache_key]['timestamp']\n",
    "        return (datetime.now() - cache_time).seconds < self.cache_duration\n",
    "    \n",
    "    def get_bars(self, symbol: str, days: int = 60) -> pd.DataFrame:\n",
    "        \"\"\"Fetch OHLCV data with caching\"\"\"\n",
    "        cache_key = self._get_cache_key(symbol, days)\n",
    "        \n",
    "        # Check cache first\n",
    "        if self._is_cache_valid(cache_key):\n",
    "            logger.info(f\"Using cached data for {symbol}\")\n",
    "            return self.cache[cache_key]['data'].copy()\n",
    "        \n",
    "        try:\n",
    "            # Fetch from API\n",
    "            end_date = datetime.now()\n",
    "            start_date = end_date - timedelta(days=days)\n",
    "            \n",
    "            bars = self.api.get_bars(\n",
    "                symbol,\n",
    "                '1Day',\n",
    "                start=start_date.strftime('%Y-%m-%d'),\n",
    "                end=end_date.strftime('%Y-%m-%d'),\n",
    "                adjustment='raw'\n",
    "            ).df\n",
    "            \n",
    "            # Reset index and clean data\n",
    "            bars = bars.reset_index()\n",
    "            bars['timestamp'] = pd.to_datetime(bars['timestamp'])\n",
    "            bars = bars.set_index('timestamp')\n",
    "            \n",
    "            # Cache the data\n",
    "            self.cache[cache_key] = {\n",
    "                'data': bars.copy(),\n",
    "                'timestamp': datetime.now()\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"Fetched {len(bars)} bars for {symbol}\")\n",
    "            return bars\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching data for {symbol}: {e}\")\n",
    "            # Return cached data if available, otherwise empty DataFrame\n",
    "            if cache_key in self.cache:\n",
    "                logger.warning(f\"Using stale cached data for {symbol}\")\n",
    "                return self.cache[cache_key]['data'].copy()\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def get_current_price(self, symbol: str) -> float:\n",
    "        \"\"\"Get current price for a symbol\"\"\"\n",
    "        try:\n",
    "            latest_trade = self.api.get_latest_trade(symbol)\n",
    "            return latest_trade.price\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting current price for {symbol}: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "class FeatureEngine:\n",
    "    \"\"\"Creates technical analysis features for ML models\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_technical_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Add 25+ technical indicators to OHLCV data\"\"\"\n",
    "        if df.empty or len(df) < 50:\n",
    "            return df\n",
    "        \n",
    "        data = df.copy()\n",
    "        \n",
    "        # Price-based features\n",
    "        data['pct_change'] = data['close'].pct_change()\n",
    "        data['log_returns'] = np.log(data['close'] / data['close'].shift(1))\n",
    "        \n",
    "        # Moving Averages\n",
    "        for period in [5, 10, 20, 50]:\n",
    "            data[f'sma_{period}'] = data['close'].rolling(period).mean()\n",
    "            data[f'ema_{period}'] = data['close'].ewm(span=period).mean()\n",
    "        \n",
    "        # Distance from moving averages\n",
    "        data['dist_from_sma20'] = (data['close'] - data['sma_20']) / data['sma_20']\n",
    "        data['dist_from_sma50'] = (data['close'] - data['sma_50']) / data['sma_50']\n",
    "        \n",
    "        # RSI\n",
    "        data['rsi_14'] = talib.RSI(data['close'].values, timeperiod=14)\n",
    "        \n",
    "        # MACD\n",
    "        macd, macd_signal, macd_hist = talib.MACD(data['close'].values, \n",
    "                                                 fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "        data['macd'] = macd\n",
    "        data['macd_signal'] = macd_signal\n",
    "        data['macd_histogram'] = macd_hist\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        bb_upper, bb_middle, bb_lower = talib.BBANDS(data['close'].values, \n",
    "                                                    timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "        data['bb_upper'] = bb_upper\n",
    "        data['bb_middle'] = bb_middle\n",
    "        data['bb_lower'] = bb_lower\n",
    "        data['bb_position'] = (data['close'] - bb_lower) / (bb_upper - bb_lower)\n",
    "        data['bb_width'] = (bb_upper - bb_lower) / bb_middle\n",
    "        \n",
    "        # ATR\n",
    "        data['atr_14'] = talib.ATR(data['high'].values, data['low'].values, \n",
    "                                  data['close'].values, timeperiod=14)\n",
    "        \n",
    "        # Rate of Change\n",
    "        data['roc_10'] = talib.ROC(data['close'].values, timeperiod=10)\n",
    "        \n",
    "        # Momentum\n",
    "        data['momentum_10'] = talib.MOM(data['close'].values, timeperiod=10)\n",
    "        \n",
    "        # Volume features\n",
    "        data['volume_sma_20'] = data['volume'].rolling(20).mean()\n",
    "        data['volume_ratio'] = data['volume'] / data['volume_sma_20']\n",
    "        \n",
    "        # Volatility\n",
    "        data['rolling_std_20'] = data['close'].rolling(20).std()\n",
    "        \n",
    "        # Gap detection\n",
    "        data['gap'] = (data['open'] - data['close'].shift(1)) / data['close'].shift(1)\n",
    "        \n",
    "        # Intraday features\n",
    "        data['high_low_ratio'] = data['high'] / data['low']\n",
    "        data['open_close_ratio'] = data['open'] / data['close']\n",
    "        \n",
    "        return data.dropna()\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_target(df: pd.DataFrame, forward_days: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"Create target variable for ML models\"\"\"\n",
    "        data = df.copy()\n",
    "        \n",
    "        # Future return calculation\n",
    "        data['future_return'] = data['close'].shift(-forward_days) / data['close'] - 1\n",
    "        \n",
    "        # Target classification\n",
    "        conditions = [\n",
    "            data['future_return'] > 0.012,   # BUY if > 1.2%\n",
    "            data['future_return'] < -0.012,  # SELL if < -1.2%\n",
    "        ]\n",
    "        choices = [1, -1]  # BUY, SELL\n",
    "        data['target'] = np.select(conditions, choices, default=0)  # HOLD\n",
    "        \n",
    "        return data.dropna()\n",
    "\n",
    "# Initialize data fetcher\n",
    "data_fetcher = DataFetcher(config.ALPACA_API_KEY, config.ALPACA_SECRET_KEY, config.ALPACA_BASE_URL)\n",
    "feature_engine = FeatureEngine()\n",
    "\n",
    "# Test data fetching for SPY\n",
    "print(\"Testing Data Layer with SPY...\")\n",
    "test_progress = tqdm(total=3, desc=\"Data Test\")\n",
    "\n",
    "# Fetch raw data\n",
    "spy_data = data_fetcher.get_bars('SPY', days=90)\n",
    "test_progress.update(1)\n",
    "\n",
    "# Add technical features\n",
    "spy_features = feature_engine.add_technical_features(spy_data)\n",
    "test_progress.update(1)\n",
    "\n",
    "# Create target variable\n",
    "spy_with_target = feature_engine.create_target(spy_features)\n",
    "test_progress.update(1)\n",
    "test_progress.close()\n",
    "\n",
    "print(f\"\\nSPY Data Summary:\")\n",
    "print(f\"Raw data shape: {spy_data.shape}\")\n",
    "print(f\"With features: {spy_features.shape}\")\n",
    "print(f\"With target: {spy_with_target.shape}\")\n",
    "print(f\"Features: {list(spy_features.columns)}\")\n",
    "\n",
    "# Display recent data sample\n",
    "print(\"\\nRecent SPY Data (last 5 days):\")\n",
    "display(spy_with_target[['close', 'rsi_14', 'macd', 'bb_position', 'volume_ratio', 'target']].tail())\n",
    "\n",
    "# Show target distribution\n",
    "if not spy_with_target.empty:\n",
    "    target_dist = spy_with_target['target'].value_counts().sort_index()\n",
    "    print(f\"\\nTarget Distribution:\")\n",
    "    print(f\"SELL (-1): {target_dist.get(-1, 0)} days ({target_dist.get(-1, 0)/len(spy_with_target):.1%})\")\n",
    "    print(f\"HOLD (0):  {target_dist.get(0, 0)} days ({target_dist.get(0, 0)/len(spy_with_target):.1%})\")\n",
    "    print(f\"BUY (1):   {target_dist.get(1, 0)} days ({target_dist.get(1, 0)/len(spy_with_target):.1%})\")\n",
    "\n",
    "print(\"\\nData Layer successfully tested!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea611d9",
   "metadata": {},
   "source": [
    "# Cell 4: Traditional Strategies\n",
    "\n",
    "This cell implements four traditional trading strategies using technical analysis.\n",
    "\n",
    "Strategy Classes:\n",
    "- RSIMeanReversionStrategy: RSI(14) + Bollinger Bands mean reversion\n",
    "- MomentumBreakoutStrategy: SMA crossover + ROC confirmation\n",
    "- MACDVolumeStrategy: MACD signals amplified by volume\n",
    "- GapStrategy: Fade gaps greater than 2%\n",
    "\n",
    "Base Class:\n",
    "- Strategy: Abstract base class with signal generation interface\n",
    "- Returns signals from -1 (strong sell) to +1 (strong buy)\n",
    "\n",
    "Demo: Calculate signals for SPY sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea17f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: TRADITIONAL STRATEGIES\n",
    "# ============================================================================\n",
    "\n",
    "class Strategy(ABC):\n",
    "    \"\"\"Abstract base class for trading strategies\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_signal(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Generate trading signal (-1 to 1)\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_name(self) -> str:\n",
    "        \"\"\"Return strategy name\"\"\"\n",
    "        pass\n",
    "\n",
    "class RSIMeanReversionStrategy(Strategy):\n",
    "    \"\"\"RSI Mean Reversion with Bollinger Bands\"\"\"\n",
    "    \n",
    "    def __init__(self, rsi_period: int = 14, bb_period: int = 20, bb_std: float = 2.0):\n",
    "        self.rsi_period = rsi_period\n",
    "        self.bb_period = bb_period\n",
    "        self.bb_std = bb_std\n",
    "    \n",
    "    def generate_signal(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Generate RSI mean reversion signal\"\"\"\n",
    "        if data.empty or len(data) < max(self.rsi_period, self.bb_period):\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            latest = data.iloc[-1]\n",
    "            rsi = latest.get('rsi_14', 50)\n",
    "            bb_position = latest.get('bb_position', 0.5)\n",
    "            \n",
    "            # RSI oversold/overbought levels\n",
    "            if rsi < 30 and bb_position < 0.2:  # Oversold\n",
    "                signal = min(1.0, (30 - rsi) / 10)  # Scale signal\n",
    "            elif rsi > 70 and bb_position > 0.8:  # Overbought\n",
    "                signal = max(-1.0, (70 - rsi) / 10)  # Scale signal\n",
    "            else:\n",
    "                signal = 0.0\n",
    "            \n",
    "            return np.clip(signal, -1.0, 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"RSI strategy error: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def get_name(self) -> str:\n",
    "        return \"RSI Mean Reversion\"\n",
    "\n",
    "class MomentumBreakoutStrategy(Strategy):\n",
    "    \"\"\"Momentum Breakout Strategy\"\"\"\n",
    "    \n",
    "    def __init__(self, fast_ma: int = 20, slow_ma: int = 50, roc_period: int = 10):\n",
    "        self.fast_ma = fast_ma\n",
    "        self.slow_ma = slow_ma\n",
    "        self.roc_period = roc_period\n",
    "    \n",
    "    def generate_signal(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Generate momentum breakout signal\"\"\"\n",
    "        if data.empty or len(data) < self.slow_ma:\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            latest = data.iloc[-1]\n",
    "            fast_ma = latest.get('sma_20', 0)\n",
    "            slow_ma = latest.get('sma_50', 0)\n",
    "            roc = latest.get('roc_10', 0)\n",
    "            \n",
    "            if fast_ma == 0 or slow_ma == 0:\n",
    "                return 0.0\n",
    "            \n",
    "            # MA crossover signal\n",
    "            ma_signal = (fast_ma - slow_ma) / slow_ma\n",
    "            \n",
    "            # ROC confirmation\n",
    "            roc_confirmation = np.tanh(roc / 5)  # Normalize ROC\n",
    "            \n",
    "            # Combined signal\n",
    "            signal = ma_signal * roc_confirmation\n",
    "            \n",
    "            return np.clip(signal, -1.0, 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Momentum strategy error: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def get_name(self) -> str:\n",
    "        return \"Momentum Breakout\"\n",
    "\n",
    "class MACDVolumeStrategy(Strategy):\n",
    "    \"\"\"MACD with Volume Confirmation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def generate_signal(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Generate MACD volume signal\"\"\"\n",
    "        if data.empty or len(data) < 26:\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            latest = data.iloc[-1]\n",
    "            macd = latest.get('macd', 0)\n",
    "            macd_signal = latest.get('macd_signal', 0)\n",
    "            volume_ratio = latest.get('volume_ratio', 1)\n",
    "            \n",
    "            # MACD crossover\n",
    "            macd_diff = macd - macd_signal\n",
    "            \n",
    "            # Volume amplification\n",
    "            volume_multiplier = min(2.0, max(0.5, volume_ratio))\n",
    "            \n",
    "            # Combined signal\n",
    "            signal = np.tanh(macd_diff / 0.01) * volume_multiplier / 2.0\n",
    "            \n",
    "            return np.clip(signal, -1.0, 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"MACD strategy error: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def get_name(self) -> str:\n",
    "        return \"MACD Volume\"\n",
    "\n",
    "class GapStrategy(Strategy):\n",
    "    \"\"\"Gap Fade Strategy\"\"\"\n",
    "    \n",
    "    def __init__(self, min_gap: float = 0.02):\n",
    "        self.min_gap = min_gap\n",
    "    \n",
    "    def generate_signal(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Generate gap fade signal\"\"\"\n",
    "        if data.empty or len(data) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            latest = data.iloc[-1]\n",
    "            gap = latest.get('gap', 0)\n",
    "            \n",
    "            # Only trade significant gaps\n",
    "            if abs(gap) < self.min_gap:\n",
    "                return 0.0\n",
    "            \n",
    "            # Fade the gap (negative correlation)\n",
    "            signal = -np.tanh(gap / 0.05)  # Scale signal\n",
    "            \n",
    "            return np.clip(signal, -1.0, 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Gap strategy error: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def get_name(self) -> str:\n",
    "        return \"Gap Fade\"\n",
    "\n",
    "# Initialize strategies\n",
    "strategies = {\n",
    "    'rsi_mean_reversion': RSIMeanReversionStrategy(),\n",
    "    'momentum_breakout': MomentumBreakoutStrategy(),\n",
    "    'macd_volume': MACDVolumeStrategy(),\n",
    "    'gap_fade': GapStrategy()\n",
    "}\n",
    "\n",
    "# Demo: Calculate signals for SPY data\n",
    "print(\"Testing Traditional Strategies with SPY...\")\n",
    "strategy_progress = tqdm(total=len(strategies), desc=\"Strategy Signals\")\n",
    "\n",
    "if not spy_with_target.empty:\n",
    "    signals = {}\n",
    "    \n",
    "    for name, strategy in strategies.items():\n",
    "        signal = strategy.generate_signal(spy_with_target)\n",
    "        signals[name] = signal\n",
    "        strategy_progress.update(1)\n",
    "        print(f\"{strategy.get_name()}: {signal:.3f}\")\n",
    "    \n",
    "    strategy_progress.close()\n",
    "    \n",
    "    # Create signals DataFrame\n",
    "    signal_df = pd.DataFrame([signals], index=['Signal'])\n",
    "    \n",
    "    print(\"\\nStrategy Signals Summary:\")\n",
    "    styled_signals = signal_df.style.background_gradient(\n",
    "        cmap='RdYlGn', center=0, vmin=-1, vmax=1\n",
    "    ).format('{:.3f}')\n",
    "    display(styled_signals)\n",
    "    \n",
    "    # Calculate ensemble signal using weights\n",
    "    ensemble_signal = sum(signals[name] * config.STRATEGY_WEIGHTS[name] \n",
    "                         for name in signals.keys())\n",
    "    print(f\"\\nTraditional Ensemble Signal: {ensemble_signal:.3f}\")\n",
    "    \n",
    "    # Visualize signals\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    signal_values = list(signals.values())\n",
    "    strategy_names = [strategies[name].get_name() for name in signals.keys()]\n",
    "    \n",
    "    colors = ['red' if x < 0 else 'green' for x in signal_values]\n",
    "    bars = ax.bar(strategy_names, signal_values, color=colors, alpha=0.7)\n",
    "    \n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.set_ylabel('Signal Strength')\n",
    "    ax.set_title('Traditional Strategy Signals for SPY')\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, signal_values):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + (0.05 if height >= 0 else -0.1),\n",
    "                f'{value:.3f}', ha='center', va='bottom' if height >= 0 else 'top')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No SPY data available for testing\")\n",
    "\n",
    "print(\"\\nTraditional strategies successfully implemented!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994712e0",
   "metadata": {},
   "source": [
    "# Cell 5: ML Models - Random Forest\n",
    "\n",
    "This cell implements the Random Forest machine learning model for signal generation.\n",
    "\n",
    "Features:\n",
    "- MLModel: Abstract base class for all ML models\n",
    "- RandomForestModel: 100 trees, max_depth=10, 3-class classification\n",
    "- Feature selection and preprocessing\n",
    "- Model persistence with pickle\n",
    "- Performance metrics and validation\n",
    "\n",
    "Target Classes:\n",
    "- -1: SELL (expected return < -1.2%)\n",
    "- 0: HOLD (expected return between -1.2% and +1.2%)\n",
    "- 1: BUY (expected return > +1.2%)\n",
    "\n",
    "Demo: Train and predict on SPY sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b2522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: ML MODELS - RANDOM FOREST\n",
    "# ============================================================================\n",
    "\n",
    "class MLModel(ABC):\n",
    "    \"\"\"Abstract base class for ML models\"\"\"\n",
    "    \n",
    "    def __init__(self, symbol: str):\n",
    "        self.symbol = symbol\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.feature_columns = None\n",
    "        self.is_trained = False\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(self, data: pd.DataFrame) -> bool:\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Generate prediction signal\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save_model(self, path: str) -> bool:\n",
    "        \"\"\"Save model to disk\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_model(self, path: str) -> bool:\n",
    "        \"\"\"Load model from disk\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def get_feature_columns(self) -> List[str]:\n",
    "        \"\"\"Get list of feature columns for ML training\"\"\"\n",
    "        return [\n",
    "            'pct_change', 'log_returns', 'sma_5', 'sma_10', 'sma_20', 'sma_50',\n",
    "            'ema_5', 'ema_10', 'ema_20', 'ema_50', 'dist_from_sma20', 'dist_from_sma50',\n",
    "            'rsi_14', 'macd', 'macd_signal', 'macd_histogram', 'bb_position', 'bb_width',\n",
    "            'atr_14', 'roc_10', 'momentum_10', 'volume_ratio', 'rolling_std_20',\n",
    "            'gap', 'high_low_ratio', 'open_close_ratio'\n",
    "        ]\n",
    "\n",
    "class RandomForestModel(MLModel):\n",
    "    \"\"\"Random Forest implementation for trading signals\"\"\"\n",
    "    \n",
    "    def __init__(self, symbol: str, n_estimators: int = 100, max_depth: int = 10, \n",
    "                 min_samples_split: int = 20):\n",
    "        super().__init__(symbol)\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.feature_columns = self.get_feature_columns()\n",
    "    \n",
    "    def train(self, data: pd.DataFrame) -> bool:\n",
    "        \"\"\"Train Random Forest model\"\"\"\n",
    "        try:\n",
    "            if data.empty or 'target' not in data.columns:\n",
    "                logger.error(f\"Invalid training data for {self.symbol}\")\n",
    "                return False\n",
    "            \n",
    "            # Prepare features\n",
    "            available_features = [col for col in self.feature_columns if col in data.columns]\n",
    "            if len(available_features) < 10:\n",
    "                logger.error(f\"Insufficient features for {self.symbol}: {len(available_features)}\")\n",
    "                return False\n",
    "            \n",
    "            X = data[available_features].copy()\n",
    "            y = data['target'].copy()\n",
    "            \n",
    "            # Remove NaN values\n",
    "            mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "            X = X[mask]\n",
    "            y = y[mask]\n",
    "            \n",
    "            if len(X) < 50:\n",
    "                logger.error(f\"Insufficient clean data for {self.symbol}: {len(X)} samples\")\n",
    "                return False\n",
    "            \n",
    "            # Scale features\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            \n",
    "            # Train model\n",
    "            self.model = RandomForestClassifier(\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_split=self.min_samples_split,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            \n",
    "            self.model.fit(X_scaled, y)\n",
    "            self.feature_columns = available_features\n",
    "            self.is_trained = True\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            train_score = self.model.score(X_scaled, y)\n",
    "            logger.info(f\"RF model trained for {self.symbol}: accuracy={train_score:.3f}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error training RF model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def predict(self, data: pd.DataFrame) -> float:\n",
    "        \"\"\"Generate prediction signal\"\"\"\n",
    "        if not self.is_trained or self.model is None:\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            # Get latest data point\n",
    "            latest = data.iloc[[-1]]\n",
    "            \n",
    "            # Prepare features\n",
    "            X = latest[self.feature_columns].copy()\n",
    "            \n",
    "            # Check for NaN values\n",
    "            if X.isna().any().any():\n",
    "                logger.warning(f\"NaN values in features for {self.symbol}\")\n",
    "                return 0.0\n",
    "            \n",
    "            # Scale features\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            \n",
    "            # Get prediction probabilities\n",
    "            proba = self.model.predict_proba(X_scaled)[0]\n",
    "            \n",
    "            # Convert to signal (-1 to 1)\n",
    "            # proba order: [class_-1, class_0, class_1] or [class_0, class_1] etc.\n",
    "            classes = self.model.classes_\n",
    "            \n",
    "            if len(classes) == 3:  # All classes present\n",
    "                sell_prob = proba[np.where(classes == -1)[0][0]] if -1 in classes else 0\n",
    "                buy_prob = proba[np.where(classes == 1)[0][0]] if 1 in classes else 0\n",
    "                signal = buy_prob - sell_prob\n",
    "            else:\n",
    "                # Handle cases where not all classes are present\n",
    "                signal = 0.0\n",
    "            \n",
    "            return np.clip(signal, -1.0, 1.0)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting with RF model for {self.symbol}: {e}\")\n",
    "            return 0.0\n",
    "    \n",
    "    def save_model(self, path: str) -> bool:\n",
    "        \"\"\"Save Random Forest model\"\"\"\n",
    "        try:\n",
    "            if not self.is_trained:\n",
    "                return False\n",
    "            \n",
    "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "            \n",
    "            model_data = {\n",
    "                'model': self.model,\n",
    "                'scaler': self.scaler,\n",
    "                'feature_columns': self.feature_columns,\n",
    "                'symbol': self.symbol\n",
    "            }\n",
    "            \n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            \n",
    "            logger.info(f\"RF model saved for {self.symbol}: {path}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving RF model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def load_model(self, path: str) -> bool:\n",
    "        \"\"\"Load Random Forest model\"\"\"\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                return False\n",
    "            \n",
    "            with open(path, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            \n",
    "            self.model = model_data['model']\n",
    "            self.scaler = model_data['scaler']\n",
    "            self.feature_columns = model_data['feature_columns']\n",
    "            self.is_trained = True\n",
    "            \n",
    "            logger.info(f\"RF model loaded for {self.symbol}: {path}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading RF model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Create models directory\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Demo: Train Random Forest on SPY\n",
    "print(\"Testing Random Forest Model with SPY...\")\n",
    "rf_progress = tqdm(total=3, desc=\"RF Training\")\n",
    "\n",
    "if not spy_with_target.empty and len(spy_with_target) > 50:\n",
    "    # Initialize model\n",
    "    rf_model = RandomForestModel('SPY')\n",
    "    rf_progress.update(1)\n",
    "    \n",
    "    # Train model\n",
    "    training_success = rf_model.train(spy_with_target)\n",
    "    rf_progress.update(1)\n",
    "    \n",
    "    if training_success:\n",
    "        # Generate prediction\n",
    "        signal = rf_model.predict(spy_with_target)\n",
    "        rf_progress.update(1)\n",
    "        rf_progress.close()\n",
    "        \n",
    "        print(f\"\\nRandom Forest Results for SPY:\")\n",
    "        print(f\"Training: {'Success' if training_success else 'Failed'}\")\n",
    "        print(f\"Current Signal: {signal:.3f}\")\n",
    "        print(f\"Features Used: {len(rf_model.feature_columns)}\")\n",
    "        \n",
    "        # Feature importance\n",
    "        if rf_model.is_trained:\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': rf_model.feature_columns,\n",
    "                'importance': rf_model.model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 10 Important Features:\")\n",
    "            display(feature_importance.head(10).style.background_gradient(cmap='Blues'))\n",
    "            \n",
    "            # Save model\n",
    "            rf_model.save_model(f'models/SPY_rf.pkl')\n",
    "            print(\"Model saved successfully\")\n",
    "        \n",
    "        # Visualize feature importance\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = feature_importance.head(15)\n",
    "        \n",
    "        plt.barh(range(len(top_features)), top_features['importance'], \n",
    "                color=plt.cm.viridis(top_features['importance'] / top_features['importance'].max()))\n",
    "        plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title('Random Forest Feature Importance (SPY)')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        rf_progress.close()\n",
    "        print(\"Random Forest training failed\")\n",
    "else:\n",
    "    rf_progress.close()\n",
    "    print(\"Insufficient data for Random Forest training\")\n",
    "\n",
    "print(\"\\nRandom Forest implementation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb3c82d",
   "metadata": {},
   "source": [
    "# Cell 6: ML Models - XGBoost\n",
    "\n",
    "This cell implements the XGBoost machine learning model for signal generation.\n",
    "\n",
    "Features:\n",
    "- XGBoost classifier for 3-class classification\n",
    "- Feature selection and preprocessing\n",
    "- Model persistence with pickle\n",
    "- Performance metrics and validation\n",
    "\n",
    "Demo: Train and predict on SPY sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc89649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostModel(MLModel):\n",
    "    \"\"\"XGBoost implementation for trading signals\"\"\"\n",
    "    def __init__(self, symbol: str, n_estimators: int = 100, max_depth: int = 6, learning_rate: float = 0.1):\n",
    "        super().__init__(symbol)\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.learning_rate = learning_rate\n",
    "        self.feature_columns = self.get_feature_columns()\n",
    "\n",
    "    def train(self, data: pd.DataFrame) -> bool:\n",
    "        try:\n",
    "            if data.empty or 'target' not in data.columns:\n",
    "                logger.error(f\"Invalid training data for {self.symbol}\")\n",
    "                return False\n",
    "            available_features = [col for col in self.feature_columns if col in data.columns]\n",
    "            if len(available_features) < 10:\n",
    "                logger.error(f\"Insufficient features for {self.symbol}: {len(available_features)}\")\n",
    "                return False\n",
    "            X = data[available_features].copy()\n",
    "            y = data['target'].copy()\n",
    "            mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "            X = X[mask]\n",
    "            y = y[mask]\n",
    "            if len(X) < 50:\n",
    "                logger.error(f\"Insufficient clean data for {self.symbol}: {len(X)} samples\")\n",
    "                return False\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "            self.model = xgb.XGBClassifier(\n",
    "                n_estimators=self.n_estimators,\n",
    "                max_depth=self.max_depth,\n",
    "                learning_rate=self.learning_rate,\n",
    "                objective='multi:softprob',\n",
    "                num_class=3,\n",
    "                random_state=42,\n",
    "                n_jobs=-1,\n",
    "                verbosity=0\n",
    "            )\n",
    "            self.model.fit(X_scaled, y)\n",
    "            self.feature_columns = available_features\n",
    "            self.is_trained = True\n",
    "            train_score = self.model.score(X_scaled, y)\n",
    "            logger.info(f\"XGB model trained for {self.symbol}: accuracy={train_score:.3f}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error training XGB model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def predict(self, data: pd.DataFrame) -> float:\n",
    "        if not self.is_trained or self.model is None:\n",
    "            return 0.0\n",
    "        try:\n",
    "            latest = data.iloc[[-1]]\n",
    "            X = latest[self.feature_columns].copy()\n",
    "            if X.isna().any().any():\n",
    "                logger.warning(f\"NaN values in features for {self.symbol}\")\n",
    "                return 0.0\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            proba = self.model.predict_proba(X_scaled)[0]\n",
    "            classes = self.model.classes_\n",
    "            if len(classes) == 3:\n",
    "                sell_prob = proba[np.where(classes == -1)[0][0]] if -1 in classes else 0\n",
    "                buy_prob = proba[np.where(classes == 1)[0][0]] if 1 in classes else 0\n",
    "                signal = buy_prob - sell_prob\n",
    "            else:\n",
    "                signal = 0.0\n",
    "            return np.clip(signal, -1.0, 1.0)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting with XGB model for {self.symbol}: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "    def save_model(self, path: str) -> bool:\n",
    "        try:\n",
    "            if not self.is_trained:\n",
    "                return False\n",
    "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "            model_data = {\n",
    "                'model': self.model,\n",
    "                'scaler': self.scaler,\n",
    "                'feature_columns': self.feature_columns,\n",
    "                'symbol': self.symbol\n",
    "            }\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(model_data, f)\n",
    "            logger.info(f\"XGB model saved for {self.symbol}: {path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving XGB model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def load_model(self, path: str) -> bool:\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                return False\n",
    "            with open(path, 'rb') as f:\n",
    "                model_data = pickle.load(f)\n",
    "            self.model = model_data['model']\n",
    "            self.scaler = model_data['scaler']\n",
    "            self.feature_columns = model_data['feature_columns']\n",
    "            self.is_trained = True\n",
    "            logger.info(f\"XGB model loaded for {self.symbol}: {path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading XGB model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Demo: Train XGBoost on SPY\n",
    "def train_xgb_demo():\n",
    "    print(\"Testing XGBoost Model with SPY...\")\n",
    "    if not spy_with_target.empty and len(spy_with_target) > 50:\n",
    "        xgb_model = XGBoostModel('SPY')\n",
    "        training_success = xgb_model.train(spy_with_target)\n",
    "        if training_success:\n",
    "            signal = xgb_model.predict(spy_with_target)\n",
    "            print(f\"\\nXGBoost Results for SPY:\")\n",
    "            print(f\"Training: {'Success' if training_success else 'Failed'}\")\n",
    "            print(f\"Current Signal: {signal:.3f}\")\n",
    "            print(f\"Features Used: {len(xgb_model.feature_columns)}\")\n",
    "            # Save model\n",
    "            xgb_model.save_model('models/SPY_xgb.pkl')\n",
    "            print(\"Model saved successfully\")\n",
    "        else:\n",
    "            print(\"XGBoost training failed\")\n",
    "    else:\n",
    "        print(\"Insufficient data for XGBoost training\")\n",
    "    print(\"\\nXGBoost implementation completed!\")\n",
    "\n",
    "train_xgb_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab40da",
   "metadata": {},
   "source": [
    "# Cell 7: ML Models - LSTM\n",
    "\n",
    "This cell implements the LSTM deep learning model for signal generation.\n",
    "\n",
    "Features:\n",
    "- LSTM neural network for sequence modeling\n",
    "- Uses TensorFlow/Keras (imported locally)\n",
    "- Model persistence with Keras\n",
    "- Performance metrics and validation\n",
    "\n",
    "Demo: Train and predict on SPY sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f563e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class LSTMModel(MLModel):\n",
    "    \"\"\"LSTM implementation for trading signals\"\"\"\n",
    "    def __init__(self, symbol: str, sequence_length: int = 30, epochs: int = 20, batch_size: int = 16):\n",
    "        super().__init__(symbol)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.feature_columns = self.get_feature_columns()\n",
    "        self.model = None\n",
    "\n",
    "    def prepare_sequences(self, data: pd.DataFrame):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - self.sequence_length):\n",
    "            X.append(data[self.feature_columns].iloc[i:i+self.sequence_length].values)\n",
    "            y.append(data['target'].iloc[i+self.sequence_length])\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    def train(self, data: pd.DataFrame) -> bool:\n",
    "        try:\n",
    "            if data.empty or 'target' not in data.columns:\n",
    "                logger.error(f\"Invalid training data for {self.symbol}\")\n",
    "                return False\n",
    "            available_features = [col for col in self.feature_columns if col in data.columns]\n",
    "            if len(available_features) < 10:\n",
    "                logger.error(f\"Insufficient features for {self.symbol}: {len(available_features)}\")\n",
    "                return False\n",
    "            data = data.dropna(subset=available_features + ['target'])\n",
    "            if len(data) < self.sequence_length + 10:\n",
    "                logger.error(f\"Insufficient data for LSTM: {len(data)} samples\")\n",
    "                return False\n",
    "            self.scaler = StandardScaler()\n",
    "            data[available_features] = self.scaler.fit_transform(data[available_features])\n",
    "            X, y = self.prepare_sequences(data)\n",
    "            y = tf.keras.utils.to_categorical(y + 1, num_classes=3)  # -1,0,1 to 0,1,2\n",
    "            self.model = Sequential([\n",
    "                LSTM(64, input_shape=(self.sequence_length, len(available_features)), return_sequences=False),\n",
    "                BatchNormalization(),\n",
    "                Dropout(0.2),\n",
    "                Dense(32, activation='relu'),\n",
    "                Dense(3, activation='softmax')\n",
    "            ])\n",
    "            self.model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "            self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, validation_split=0.2, callbacks=[es], verbose=0)\n",
    "            self.is_trained = True\n",
    "            logger.info(f\"LSTM model trained for {self.symbol}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error training LSTM model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def predict(self, data: pd.DataFrame) -> float:\n",
    "        if not self.is_trained or self.model is None:\n",
    "            return 0.0\n",
    "        try:\n",
    "            available_features = [col for col in self.feature_columns if col in data.columns]\n",
    "            if len(data) < self.sequence_length:\n",
    "                return 0.0\n",
    "            X = data[available_features].tail(self.sequence_length).values\n",
    "            X = self.scaler.transform(X)\n",
    "            X = X.reshape(1, self.sequence_length, len(available_features))\n",
    "            proba = self.model.predict(X, verbose=0)[0]\n",
    "            signal = proba[2] - proba[0]  # class 2 (buy) - class 0 (sell)\n",
    "            return np.clip(signal, -1.0, 1.0)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting with LSTM model for {self.symbol}: {e}\")\n",
    "            return 0.0\n",
    "\n",
    "    def save_model(self, path: str) -> bool:\n",
    "        try:\n",
    "            if not self.is_trained:\n",
    "                return False\n",
    "            os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "            self.model.save(path)\n",
    "            logger.info(f\"LSTM model saved for {self.symbol}: {path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving LSTM model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "\n",
    "    def load_model(self, path: str) -> bool:\n",
    "        try:\n",
    "            if not os.path.exists(path):\n",
    "                return False\n",
    "            self.model = load_model(path)\n",
    "            self.is_trained = True\n",
    "            logger.info(f\"LSTM model loaded for {self.symbol}: {path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading LSTM model for {self.symbol}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Demo: Train LSTM on SPY\n",
    "def train_lstm_demo():\n",
    "    print(\"Testing LSTM Model with SPY...\")\n",
    "    if not spy_with_target.empty and len(spy_with_target) > 50:\n",
    "        lstm_model = LSTMModel('SPY')\n",
    "        training_success = lstm_model.train(spy_with_target)\n",
    "        if training_success:\n",
    "            signal = lstm_model.predict(spy_with_target)\n",
    "            print(f\"\\nLSTM Results for SPY:\")\n",
    "            print(f\"Training: {'Success' if training_success else 'Failed'}\")\n",
    "            print(f\"Current Signal: {signal:.3f}\")\n",
    "            print(f\"Features Used: {len(lstm_model.feature_columns)}\")\n",
    "            # Save model\n",
    "            lstm_model.save_model('models/SPY_lstm.keras')\n",
    "            print(\"Model saved successfully\")\n",
    "        else:\n",
    "            print(\"LSTM training failed\")\n",
    "    else:\n",
    "        print(\"Insufficient data for LSTM training\")\n",
    "    print(\"\\nLSTM implementation completed!\")\n",
    "\n",
    "train_lstm_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70212cd3",
   "metadata": {},
   "source": [
    "# Cell 8: Signal Aggregator\n",
    "\n",
    "This cell aggregates signals from all traditional and ML models using ensemble weighting.\n",
    "\n",
    "Features:\n",
    "- Combines signals from all strategies and models\n",
    "- Uses weights from configuration\n",
    "- Outputs final ensemble signal for each symbol\n",
    "\n",
    "Demo: Aggregate signals for SPY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65921bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_signals(signals: dict, weights: dict) -> float:\n",
    "    \"\"\"Aggregate signals using ensemble weights\"\"\"\n",
    "    return sum(signals[name] * weights.get(name, 0) for name in signals.keys())\n",
    "\n",
    "# Demo: Aggregate all signals for SPY\n",
    "def aggregate_demo():\n",
    "    print(\"Aggregating all signals for SPY...\")\n",
    "    # Assume signals dict from previous cells\n",
    "    signals = {}\n",
    "    # Traditional strategies\n",
    "    for name, strategy in strategies.items():\n",
    "        signals[name] = strategy.generate_signal(spy_with_target)\n",
    "    # ML models\n",
    "    rf_model = RandomForestModel('SPY')\n",
    "    xgb_model = XGBoostModel('SPY')\n",
    "    lstm_model = LSTMModel('SPY')\n",
    "    rf_model.load_model('models/SPY_rf.pkl')\n",
    "    xgb_model.load_model('models/SPY_xgb.pkl')\n",
    "    lstm_model.load_model('models/SPY_lstm.keras')\n",
    "    signals['random_forest'] = rf_model.predict(spy_with_target)\n",
    "    signals['xgboost'] = xgb_model.predict(spy_with_target)\n",
    "    signals['lstm'] = lstm_model.predict(spy_with_target)\n",
    "    # Aggregate\n",
    "    ensemble_signal = aggregate_signals(signals, config.STRATEGY_WEIGHTS)\n",
    "    print(f\"Ensemble Signal for SPY: {ensemble_signal:.3f}\")\n",
    "    return ensemble_signal\n",
    "\n",
    "aggregate_demo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481eb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c9a2251",
   "metadata": {},
   "source": [
    "# Cell 9: Risk Management\n",
    "\n",
    "This cell implements robust risk management for the trading bot.\n",
    "\n",
    "Features:\n",
    "- Position sizing based on capital, volatility, and config limits\n",
    "- Stop loss and take profit enforcement\n",
    "- Daily loss circuit breaker\n",
    "- Modular, reusable functions\n",
    "\n",
    "Demo: Calculate position size and risk checks for SPY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4766f9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: RISK MANAGEMENT\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_position_size(symbol: str, price: float, capital: float, config: TradingConfig, volatility: float = None) -> float:\n",
    "    \"\"\"Calculate position size based on risk and config limits\"\"\"\n",
    "    max_position_value = capital * config.MAX_POSITION_PCT\n",
    "    min_position_value = config.MIN_POSITION_VALUE\n",
    "    if volatility is not None and volatility > 0:\n",
    "        # Volatility-based sizing (optional)\n",
    "        risk_per_trade = capital * 0.01  # 1% risk per trade\n",
    "        size = risk_per_trade / (volatility * price)\n",
    "        position_value = min(max(size * price, min_position_value), max_position_value)\n",
    "    else:\n",
    "        position_value = max(min_position_value, min(max_position_value, capital * 0.05))\n",
    "    shares = int(position_value // price)\n",
    "    return max(shares, 0)\n",
    "\n",
    "def apply_stop_loss_take_profit(entry_price: float, current_price: float, config: TradingConfig) -> str:\n",
    "    \"\"\"Check if stop loss or take profit is triggered\"\"\"\n",
    "    change = (current_price - entry_price) / entry_price\n",
    "    if change <= -config.STOP_LOSS:\n",
    "        return \"stop_loss\"\n",
    "    elif change >= config.TAKE_PROFIT:\n",
    "        return \"take_profit\"\n",
    "    return \"hold\"\n",
    "\n",
    "def check_daily_loss(pnl_history: list, config: TradingConfig) -> bool:\n",
    "    \"\"\"Check if daily loss exceeds circuit breaker threshold\"\"\"\n",
    "    today = datetime.now().date()\n",
    "    daily_pnl = sum(pnl for date, pnl in pnl_history if date == today)\n",
    "    if daily_pnl < -config.INITIAL_CAPITAL * config.MAX_DAILY_LOSS_PCT:\n",
    "        logger.warning(f\"Daily loss limit reached: {daily_pnl:.2f}\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Demo: Risk management for SPY\n",
    "print(\"Testing Risk Management for SPY...\")\n",
    "capital = config.INITIAL_CAPITAL\n",
    "price = spy_with_target['close'].iloc[-1] if not spy_with_target.empty else 450.0\n",
    "volatility = spy_with_target['rolling_std_20'].iloc[-1] if 'rolling_std_20' in spy_with_target.columns else 2.0\n",
    "shares = calculate_position_size('SPY', price, capital, config, volatility)\n",
    "print(f\"Calculated position size for SPY: {shares} shares at ${price:.2f}\")\n",
    "\n",
    "# Simulate stop loss/take profit\n",
    "entry_price = price\n",
    "for pct_move in [-0.04, 0.02, 0.08]:\n",
    "    test_price = entry_price * (1 + pct_move)\n",
    "    result = apply_stop_loss_take_profit(entry_price, test_price, config)\n",
    "    print(f\"Entry: ${entry_price:.2f}, Current: ${test_price:.2f}, Result: {result}\")\n",
    "\n",
    "# Simulate daily loss circuit breaker\n",
    "pnl_history = [(datetime.now().date(), -3500)]  # Example: -$3,500 loss today\n",
    "if check_daily_loss(pnl_history, config):\n",
    "    print(\"Circuit breaker triggered: Trading halted for today.\")\n",
    "else:\n",
    "    print(\"No circuit breaker triggered.\")\n",
    "\n",
    "print(\"\\nRisk management logic successfully tested!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16616684",
   "metadata": {},
   "source": [
    "# Cell 9: Risk Management\n",
    "\n",
    "This cell implements robust risk management and position sizing logic for the trading bot.\n",
    "\n",
    "Features:\n",
    "- Position sizing based on risk and capital\n",
    "- Stop loss and take profit enforcement\n",
    "- Daily circuit breaker for loss limits\n",
    "- Exposure and position checks\n",
    "- Logging and error handling\n",
    "\n",
    "Demo: Calculate position size and risk checks for SPY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: RISK MANAGEMENT\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_position_size(price: float, capital: float, max_pct: float, min_value: float) -> int:\n",
    "    \"\"\"Calculate position size based on risk and capital\"\"\"\n",
    "    max_position_value = capital * max_pct\n",
    "    shares = int(max(max_position_value // price, min_value // price))\n",
    "    return max(shares, 0)\n",
    "\n",
    "def check_stop_loss(entry_price: float, current_price: float, stop_loss: float) -> bool:\n",
    "    \"\"\"Check if stop loss should be triggered\"\"\"\n",
    "    return (current_price <= entry_price * (1 - stop_loss))\n",
    "\n",
    "def check_take_profit(entry_price: float, current_price: float, take_profit: float) -> bool:\n",
    "    \"\"\"Check if take profit should be triggered\"\"\"\n",
    "    return (current_price >= entry_price * (1 + take_profit))\n",
    "\n",
    "def check_daily_loss(starting_equity: float, current_equity: float, max_daily_loss_pct: float) -> bool:\n",
    "    \"\"\"Check if daily loss exceeds circuit breaker\"\"\"\n",
    "    loss = (starting_equity - current_equity) / starting_equity\n",
    "    return loss >= max_daily_loss_pct\n",
    "\n",
    "def check_exposure(positions: dict, capital: float, max_total_exposure: float) -> bool:\n",
    "    \"\"\"Check if total exposure exceeds allowed limit\"\"\"\n",
    "    total_exposure = sum(pos['market_value'] for pos in positions.values())\n",
    "    return total_exposure <= capital * max_total_exposure\n",
    "\n",
    "# Demo: Risk management checks for SPY\n",
    "print(\"Testing Risk Management for SPY...\")\n",
    "capital = config.INITIAL_CAPITAL\n",
    "price = spy_with_target['close'].iloc[-1] if not spy_with_target.empty else 450.0\n",
    "shares = calculate_position_size(price, capital, config.MAX_POSITION_PCT, config.MIN_POSITION_VALUE)\n",
    "entry_price = price\n",
    "current_price = price * 0.97  # Simulate 3% drop\n",
    "stop_loss_triggered = check_stop_loss(entry_price, current_price, config.STOP_LOSS)\n",
    "take_profit_triggered = check_take_profit(entry_price, price * 1.08, config.TAKE_PROFIT)\n",
    "daily_loss_triggered = check_daily_loss(capital, capital * 0.96, config.MAX_DAILY_LOSS_PCT)\n",
    "\n",
    "print(f\"Position size for SPY: {shares} shares at ${price:.2f}\")\n",
    "print(f\"Stop loss triggered: {stop_loss_triggered}\")\n",
    "print(f\"Take profit triggered: {take_profit_triggered}\")\n",
    "print(f\"Daily loss circuit breaker: {daily_loss_triggered}\")\n",
    "\n",
    "print(\"\\nRisk management logic successfully tested!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa73f2e",
   "metadata": {},
   "source": [
    "# Cell 10: Order Execution\n",
    "\n",
    "This cell implements order execution logic using the Alpaca API.\n",
    "\n",
    "Features:\n",
    "- Place market orders (buy/sell)\n",
    "- Check order status and handle errors\n",
    "- Cancel open orders if needed\n",
    "- Logging and exception handling\n",
    "\n",
    "Demo: Place a simulated order for SPY (paper trading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18ce39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: ORDER EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "class OrderExecutor:\n",
    "    \"\"\"Handles order placement and management via Alpaca API\"\"\"\n",
    "    def __init__(self, api_key: str, secret_key: str, base_url: str):\n",
    "        self.client = TradingClient(api_key, secret_key, paper=True)\n",
    "\n",
    "    def place_order(self, symbol: str, qty: int, side: str, time_in_force: str = 'gtc') -> Optional[str]:\n",
    "        try:\n",
    "            order = self.client.submit_order(\n",
    "                order_data=MarketOrderRequest(\n",
    "                    symbol=symbol,\n",
    "                    qty=qty,\n",
    "                    side=OrderSide.BUY if side == 'buy' else OrderSide.SELL,\n",
    "                    time_in_force=TimeInForce.GTC\n",
    "                )\n",
    "            )\n",
    "            logger.info(f\"Order placed: {side.upper()} {qty} {symbol}\")\n",
    "            return order.id\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Order placement failed for {symbol}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_order_status(self, order_id: str) -> Optional[str]:\n",
    "        try:\n",
    "            order = self.client.get_order_by_id(order_id)\n",
    "            logger.info(f\"Order {order_id} status: {order.status}\")\n",
    "            return order.status\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get order status: {e}\")\n",
    "            return None\n",
    "\n",
    "    def cancel_order(self, order_id: str) -> bool:\n",
    "        try:\n",
    "            self.client.cancel_order_by_id(order_id)\n",
    "            logger.info(f\"Order {order_id} cancelled\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to cancel order {order_id}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Demo: Place a simulated order for SPY\n",
    "print(\"Testing Order Execution for SPY...\")\n",
    "order_executor = OrderExecutor(config.ALPACA_API_KEY, config.ALPACA_SECRET_KEY, config.ALPACA_BASE_URL)\n",
    "order_id = order_executor.place_order('SPY', 10, 'buy')\n",
    "if order_id:\n",
    "    status = order_executor.get_order_status(order_id)\n",
    "    print(f\"Order status: {status}\")\n",
    "    # Cancel for demo\n",
    "    cancelled = order_executor.cancel_order(order_id)\n",
    "    print(f\"Order cancelled: {cancelled}\")\n",
    "else:\n",
    "    print(\"Order placement failed (check API keys and paper trading mode)\")\n",
    "\n",
    "print(\"\\nOrder execution logic successfully tested!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726e1dc",
   "metadata": {},
   "source": [
    "# Cell 11: Main Bot Orchestrator\n",
    "\n",
    "This cell implements the main trading bot orchestrator, integrating all modules.\n",
    "\n",
    "Features:\n",
    "- Main trading loop (single run or scheduled)\n",
    "- Fetches data, generates signals, applies risk management, and executes orders\n",
    "- Modular integration of strategies, ML models, and risk controls\n",
    "- Logging and error handling\n",
    "\n",
    "Demo: Simulate a single trading loop for SPY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c23b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: MAIN BOT ORCHESTRATOR\n",
    "# ============================================================================\n",
    "\n",
    "def main_trading_loop(symbol: str, capital: float):\n",
    "    print(f\"\\nRunning main trading loop for {symbol}...\")\n",
    "    # Fetch data\n",
    "    data = data_fetcher.get_bars(symbol, days=config.ML_LOOKBACK)\n",
    "    features = feature_engine.add_technical_features(data)\n",
    "    features = feature_engine.create_target(features)\n",
    "    if features.empty:\n",
    "        print(\"No data available for trading.\")\n",
    "        return\n",
    "    # Generate signals\n",
    "    signals = {}\n",
    "    for name, strategy in strategies.items():\n",
    "        signals[name] = strategy.generate_signal(features)\n",
    "    rf_model = RandomForestModel(symbol)\n",
    "    xgb_model = XGBoostModel(symbol)\n",
    "    lstm_model = LSTMModel(symbol)\n",
    "    rf_model.load_model(f'models/{symbol}_rf.pkl')\n",
    "    xgb_model.load_model(f'models/{symbol}_xgb.pkl')\n",
    "    lstm_model.load_model(f'models/{symbol}_lstm.keras')\n",
    "    signals['random_forest'] = rf_model.predict(features)\n",
    "    signals['xgboost'] = xgb_model.predict(features)\n",
    "    signals['lstm'] = lstm_model.predict(features)\n",
    "    # Aggregate\n",
    "    ensemble_signal = aggregate_signals(signals, config.STRATEGY_WEIGHTS)\n",
    "    print(f\"Ensemble signal: {ensemble_signal:.3f}\")\n",
    "    # Risk management\n",
    "    price = features['close'].iloc[-1]\n",
    "    shares = calculate_position_size(price, capital, config.MAX_POSITION_PCT, config.MIN_POSITION_VALUE)\n",
    "    if abs(ensemble_signal) < config.MIN_SIGNAL_STRENGTH:\n",
    "        print(\"Signal not strong enough to trade.\")\n",
    "        return\n",
    "    # Order execution\n",
    "    order_executor = OrderExecutor(config.ALPACA_API_KEY, config.ALPACA_SECRET_KEY, config.ALPACA_BASE_URL)\n",
    "    side = 'buy' if ensemble_signal > 0 else 'sell'\n",
    "    order_id = order_executor.place_order(symbol, shares, side)\n",
    "    if order_id:\n",
    "        print(f\"Order placed: {side} {shares} {symbol}\")\n",
    "    else:\n",
    "        print(\"Order placement failed.\")\n",
    "\n",
    "# Demo: Simulate a single trading loop for SPY\n",
    "main_trading_loop('SPY', config.INITIAL_CAPITAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c389c5c",
   "metadata": {},
   "source": [
    "# Cell 12: Testing & Validation\n",
    "\n",
    "This cell implements backtesting and validation routines for the trading bot.\n",
    "\n",
    "Features:\n",
    "- Historical backtesting of strategies and ML models\n",
    "- Performance metrics: returns, Sharpe ratio, drawdown\n",
    "- Validation of signal accuracy\n",
    "- Visualization of results\n",
    "\n",
    "Demo: Backtest ensemble strategy on SPY historical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: TESTING & VALIDATION\n",
    "# ============================================================================\n",
    "\n",
    "def backtest_ensemble_strategy(symbol: str, data: pd.DataFrame, initial_capital: float = 100000):\n",
    "    print(f\"\\nBacktesting ensemble strategy for {symbol}...\")\n",
    "    if data.empty:\n",
    "        print(\"No data for backtest.\")\n",
    "        return\n",
    "    capital = initial_capital\n",
    "    positions = []\n",
    "    returns = []\n",
    "    for i in range(30, len(data)):\n",
    "        window = data.iloc[:i+1]\n",
    "        # Generate signals\n",
    "        signals = {name: strategy.generate_signal(window) for name, strategy in strategies.items()}\n",
    "        rf_model = RandomForestModel(symbol)\n",
    "        xgb_model = XGBoostModel(symbol)\n",
    "        lstm_model = LSTMModel(symbol)\n",
    "        rf_model.load_model(f'models/{symbol}_rf.pkl')\n",
    "        xgb_model.load_model(f'models/{symbol}_xgb.pkl')\n",
    "        lstm_model.load_model(f'models/{symbol}_lstm.keras')\n",
    "        signals['random_forest'] = rf_model.predict(window)\n",
    "        signals['xgboost'] = xgb_model.predict(window)\n",
    "        signals['lstm'] = lstm_model.predict(window)\n",
    "        ensemble_signal = aggregate_signals(signals, config.STRATEGY_WEIGHTS)\n",
    "        # Position sizing\n",
    "        price = window['close'].iloc[-1]\n",
    "        shares = calculate_position_size(price, capital, config.MAX_POSITION_PCT, config.MIN_POSITION_VALUE)\n",
    "        # Simulate trade\n",
    "        if ensemble_signal > config.MIN_SIGNAL_STRENGTH:\n",
    "            # Buy\n",
    "            entry_price = price\n",
    "            exit_price = price * (1 + config.TAKE_PROFIT)\n",
    "            pnl = (exit_price - entry_price) * shares\n",
    "            capital += pnl\n",
    "            returns.append(pnl / (entry_price * shares))\n",
    "        elif ensemble_signal < -config.MIN_SIGNAL_STRENGTH:\n",
    "            # Sell\n",
    "            entry_price = price\n",
    "            exit_price = price * (1 - config.STOP_LOSS)\n",
    "            pnl = (entry_price - exit_price) * shares\n",
    "            capital += pnl\n",
    "            returns.append(pnl / (entry_price * shares))\n",
    "        else:\n",
    "            returns.append(0)\n",
    "    # Performance metrics\n",
    "    returns = np.array(returns)\n",
    "    total_return = np.sum(returns)\n",
    "    sharpe = np.mean(returns) / (np.std(returns) + 1e-6) * np.sqrt(252)\n",
    "    max_drawdown = np.max(np.maximum.accumulate(np.cumsum(returns)) - np.cumsum(returns))\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown:.2%}\")\n",
    "    # Plot returns\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(np.cumsum(returns), label='Cumulative Return')\n",
    "    plt.title(f'Backtest Cumulative Return: {symbol}')\n",
    "    plt.xlabel('Trade Number')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Demo: Backtest on SPY\n",
    "data = spy_with_target.copy()\n",
    "backtest_ensemble_strategy('SPY', data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7394563",
   "metadata": {},
   "source": [
    "# Cell 13: Production Run\n",
    "\n",
    "This cell implements the live trading loop for production deployment.\n",
    "\n",
    "Features:\n",
    "- Continuous trading loop with scheduling\n",
    "- Real-time data fetching, signal generation, and order execution\n",
    "- Logging and error handling\n",
    "- Graceful shutdown and circuit breaker\n",
    "\n",
    "Note: For demo, this cell will not run an infinite loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 13: PRODUCTION RUN\n",
    "# ============================================================================\n",
    "\n",
    "import time\n",
    "\n",
    "def production_trading_run(symbols: list, capital: float):\n",
    "    print(\"\\nStarting production trading run (demo mode)...\")\n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            main_trading_loop(symbol, capital)\n",
    "            time.sleep(1)  # Simulate interval\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in production run for {symbol}: {e}\")\n",
    "    print(\"Production trading run completed (demo mode).\")\n",
    "\n",
    "# Demo: Run production loop for first 3 symbols\n",
    "production_trading_run(config.SYMBOLS[:3], config.INITIAL_CAPITAL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac4962e",
   "metadata": {},
   "source": [
    "# Cell 14: Performance Monitoring\n",
    "\n",
    "This cell implements performance monitoring, reporting, and visualization for the trading bot.\n",
    "\n",
    "Features:\n",
    "- Track key metrics: returns, win rate, drawdown, exposure\n",
    "- Generate performance reports\n",
    "- Visualize trading results and equity curve\n",
    "\n",
    "Demo: Visualize SPY backtest results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadc483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 14: PERFORMANCE MONITORING\n",
    "# ============================================================================\n",
    "\n",
    "def performance_report(returns: np.ndarray):\n",
    "    print(\"\\nPerformance Report:\")\n",
    "    total_return = np.sum(returns)\n",
    "    win_rate = np.mean(returns > 0)\n",
    "    sharpe = np.mean(returns) / (np.std(returns) + 1e-6) * np.sqrt(252)\n",
    "    max_drawdown = np.max(np.maximum.accumulate(np.cumsum(returns)) - np.cumsum(returns))\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    print(f\"Win Rate: {win_rate:.2%}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "    print(f\"Max Drawdown: {max_drawdown:.2%}\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(np.cumsum(returns), label='Cumulative Return')\n",
    "    plt.title('Equity Curve')\n",
    "    plt.xlabel('Trade Number')\n",
    "    plt.ylabel('Cumulative Return')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Demo: Use returns from previous backtest (if available)\n",
    "try:\n",
    "    performance_report(np.array(returns))\n",
    "except Exception:\n",
    "    print(\"No returns data available for performance report.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8dbab",
   "metadata": {},
   "source": [
    "# Cell 15: Manual Controls\n",
    "\n",
    "This cell provides manual controls for the trading bot using interactive widgets.\n",
    "\n",
    "Features:\n",
    "- Interactive widgets for manual trade override\n",
    "- Emergency stop button\n",
    "- Real-time status display\n",
    "\n",
    "Demo: Manual trade controls for SPY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c2381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 15: MANUAL CONTROLS\n",
    "# ============================================================================\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "symbol_dropdown = widgets.Dropdown(options=config.SYMBOLS, value='SPY', description='Symbol:')\n",
    "qty_slider = widgets.IntSlider(value=10, min=1, max=100, step=1, description='Qty:')\n",
    "side_dropdown = widgets.Dropdown(options=['buy', 'sell'], value='buy', description='Side:')\n",
    "trade_button = widgets.Button(description='Place Trade', button_style='success')\n",
    "emergency_stop = widgets.Button(description='EMERGENCY STOP', button_style='danger')\n",
    "output = widgets.Output()\n",
    "\n",
    "order_executor = OrderExecutor(config.ALPACA_API_KEY, config.ALPACA_SECRET_KEY, config.ALPACA_BASE_URL)\n",
    "\n",
    "@output.capture()\n",
    "def on_trade_clicked(b):\n",
    "    symbol = symbol_dropdown.value\n",
    "    qty = qty_slider.value\n",
    "    side = side_dropdown.value\n",
    "    order_id = order_executor.place_order(symbol, qty, side)\n",
    "    if order_id:\n",
    "        print(f\"Manual order placed: {side} {qty} {symbol}\")\n",
    "    else:\n",
    "        print(\"Order placement failed.\")\n",
    "\n",
    "def on_emergency_stop(b):\n",
    "    print(\"EMERGENCY STOP ACTIVATED! All trading halted.\")\n",
    "    # In production, implement logic to halt all trading and cancel open orders\n",
    "\n",
    "trade_button.on_click(on_trade_clicked)\n",
    "emergency_stop.on_click(on_emergency_stop)\n",
    "\n",
    "controls = widgets.VBox([\n",
    "    symbol_dropdown, qty_slider, side_dropdown, trade_button, emergency_stop, output\n",
    "])\n",
    "display(controls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c936e",
   "metadata": {},
   "source": [
    "# Notebook Complete: Final Review & Next Steps\n",
    "\n",
    "Congratulations! The modular, production-ready ML-Enhanced Algorithmic Trading Bot for Alpaca API is now fully implemented.\n",
    "\n",
    "**Next Steps:**\n",
    "- Review and test each cell in your environment\n",
    "- Train and persist models for all symbols in your universe\n",
    "- Configure environment variables and API keys securely\n",
    "- Deploy in paper trading mode before going live\n",
    "- Monitor logs and performance metrics regularly\n",
    "\n",
    "For any issues, consult the documentation and logs. Trade responsibly!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algotrade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
